---
title: "Holly's Dissertation"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tableone)
library(car)
library(skimr)
library(knitr)
library(tidyverse)
library(lme4)
library(nlme)
library(glmmLasso)
```

```{r echo=FALSE,include=FALSE}
# import data
dat <- read.csv("/Volumes/som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Holly O'Donnell/Dissertation/Data_Raw/data_7.7.19.csv",na.strings = "")
# format and fill down date of birth,diagnosis date, income level
dat$DateofBirth <- lubridate::mdy(dat$DateofBirth)
dat$DiagnosisDate <- lubridate::mdy(dat$DiagnosisDate)
dat <- dat %>% group_by(ID) %>% fill(DateofBirth) %>% fill(IncomeLevel) %>% fill(DiagnosisDate)
# format visit date
dat$VisitDate <- lubridate::mdy(dat$VisitDate)
# Calculate age and T1D duration at each visit
dat$age_days <- difftime(dat$VisitDate,dat$DateofBirth,units = "days")
dat$age_years <- as.numeric(dat$age_days / 365.25)
dat$T1D_dur_days <- difftime(dat$VisitDate,dat$DiagnosisDate,units = "days")
dat$T1D_dur_years <- as.numeric(dat$T1D_dur_days / 365.25)
# Make study visit and treatment categorical
dat$StudyVisit <- as.factor(dat$StudyVisit)
dat$Treatment <- as.factor(dat$Treatment)
```

# Model Selection (BG checks per day)

## Start with the full model

```{r echo=FALSE,include=FALSE}
#LME4 models to check convergence
full_mod_l <- lmer(readings_per_day ~ Treatment + StudyVisit + HbA1c + age_years + T1D_dur_years + IncomeLevel + (1|ID), data = dat)
reduced_mod_l <- lmer(readings_per_day ~ Treatment + StudyVisit + HbA1c + age_years + (1|ID), data = dat)
```

```{r}
full_mod <- lme(readings_per_day ~ Treatment + StudyVisit + HbA1c + age_years + T1D_dur_years + IncomeLevel,
            random =~1|ID, data = dat,na.action = na.omit)
```

### Check variance inflation factor

```{r echo=FALSE}
vif <- as.data.frame(vif(full_mod))
kable(vif)
```

In general, VIF > 10 is a concern so it looks like we don't need to worry about multicollinearity here.

### Full model results

```{r echo=FALSE}
kable(summary(full_mod)$tTable)
```

T1D duration and income level are not significant, so check the reduced model without those. 

## Reduced model

```{r}
reduced_mod <- lme(readings_per_day ~ Treatment + StudyVisit + HbA1c + age_years,
                   random =~1|ID, data = dat,na.action = na.omit) 
```

### Compare AIC

```{r warning=FALSE}
kable(AIC(full_mod,reduced_mod))
```

Lower AIC is better, so  this indicates that the full model is actually a better fit. Now compare the full model to a model with T1D duration and a model with income level. 

## Semi-reduced models

```{r}
t1d_dur_mod <- lme(readings_per_day ~ Treatment + StudyVisit + HbA1c + age_years + T1D_dur_years,
                   random =~1|ID, data = dat,na.action = na.omit)
income_mod <- lme(readings_per_day ~ Treatment + StudyVisit + HbA1c + age_years + IncomeLevel,
                   random =~1|ID, data = dat,na.action = na.omit)
```

### Compare AIC

```{r echo=FALSE,warning=FALSE}
kable(AIC(full_mod,t1d_dur_mod,income_mod,reduced_mod))
```

Based on AIC, the model adjusted for age, HbA1c, and income level is best. 

# LASSO Variable Selection

```{r echo=FALSE,cache=TRUE}
# Select only the necessary columns
lasso_data <- dat %>% dplyr::select(ID,readings_per_day,Treatment,StudyVisit,HbA1c,age_years,T1D_dur_years,IncomeLevel)
# Complete cases
lasso_data <- lasso_data[complete.cases(lasso_data),]
# ID as a factor
lasso_data$ID <- as.factor(lasso_data$ID)
# Convert from tibble to dataframe
lasso_data <- as.data.frame(lasso_data)
# Use BIC to find optimal tuning parameter lambda (from glmmLasso demo)
lambda <- seq(500,0,by=-1)
AIC_vec<-rep(Inf,length(lambda))
for(j in 1:length(lambda)){
glm1 <- try(glmmLasso(readings_per_day ~ as.factor(Treatment) + as.factor(StudyVisit) + HbA1c + age_years + T1D_dur_years + as.factor(IncomeLevel),data = lasso_data,rnd = list(ID=~1),lambda = lambda[j],final.re=TRUE))  
if(class(glm1)!="try-error"){AIC_vec[j]<-glm1$aic}}
opt<-which.min(AIC_vec)
```

```{r}
lasso <- glmmLasso(readings_per_day ~ as.factor(Treatment) + as.factor(StudyVisit) + HbA1c + age_years + T1D_dur_years + as.factor(IncomeLevel),data = lasso_data,rnd = list(ID=~1),lambda = lambda[opt],final.re=TRUE)
```

```{r echo=FALSE}
kable(summary(lasso)$coefficients)
```

LASSO regression using AIC to determine the optimal shrinkage parameter agrees with our model selection, which is a good sign. It removes the visit variable from the model, but makes sense since study visit wasn't significant in our model. LASSO is not a necessary step in the model selection process, but I (Tim) have been wanting to try it out and this seemed like a good opportunity!

# Check models for another outcome (% high boluses without carb)

```{r}
bolus_mod_full <- lme(highBG_without_carb_with_bolus ~ Treatment + StudyVisit + HbA1c + age_years + T1D_dur_years + IncomeLevel,
                      random =~1|ID, data = dat,na.action = na.omit)
bolus_mod_income <- lme(highBG_without_carb_with_bolus ~ Treatment + StudyVisit + HbA1c + age_years + IncomeLevel,
                        random =~1|ID, data = dat,na.action = na.omit)
bolus_mod_reduced <- lme(highBG_without_carb_with_bolus ~ Treatment + StudyVisit + HbA1c + age_years,
                        random =~1|ID, data = dat,na.action = na.omit)
```

```{r echo=FALSE,warning=FALSE}
kable(AIC(bolus_mod_full,bolus_mod_income,bolus_mod_reduced))
```

Technically the full model is better than the income model, because AIC is lower by 2.618 (the general rule of thumb is that a difference of 2 is significant). However, since they are pretty close I think it makes sense to use the same model structure for all of your outcomes, to help with the interpretation of the results. 