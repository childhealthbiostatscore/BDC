---
title: "JDRF Models"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Volumes/som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Greg Forlenza/JDRF")
library(Hmisc)
library(arsenal)
library(skimr)
library(knitr)
library(Epi)
library(glmnet)
library(tidyverse)
```

```{r import data,echo=FALSE}
source("/Users/timvigers/GitHub/BDC-Code/Greg Forlenza/JDRF/data_import.R")
# Exclude participants after 115 and those who never started AM
exclude <- data$record_id[which(data$gyl_timepoint==0 & is.na(data$automode_start))]
data <- data %>% filter(record_id <= 115,!(record_id %in% exclude))
```

```{r data cleaning,echo=FALSE,message=FALSE}
# Binary endpoint and predictors
# The primary endpoint of interest will be percent time in closed loop at 1 year 
# captured as a continuous percentage for the 2 weeks prior to the 1 year clinical 
# follow up visit, and will be converted to a binary variable with ≥60% representing 
# successful AP use and <60% representing unsuccessful AP use.
df <- left_join(data %>% group_by(record_id) %>% 
                  filter(gyl_timepoint.factor =="12 Months" | 
                           gyl_timepoint.factor =="9 Months") %>%
                  filter(row_number() == n()) %>%
                  summarise(am_final = time_am), 
                data %>% filter(grepl("baseline",redcap_event_name)),
                by = "record_id")
# Remove duplicates
df <- df[-c(which(duplicated(df$record_id))-1),]
# PAID
df$c_paid_total <- 
  apply(df[,which(colnames(df)=="c_paid1"):
                  which(colnames(df)=="c_paid20")],1,
        function(x){mean(5-x)*25})
df$ya_paid_total <- 
  apply(df[,which(colnames(df)=="ya_paid1"):
                  which(colnames(df)=="ya_paid20")],1,
        function(x){sum(x)*1.25})
# HFS behave
df$c_hfs_behave_total <- 
  apply(df[,which(colnames(df)=="c_hfs_behave1"):
                  which(colnames(df)=="c_hfs_behave10")],1,
        function(x){sum(x)})
df$ya_hfs_behave_total <- 
  apply(df[,which(colnames(df)=="ya_hfs_b_behave1"):
                  which(colnames(df)=="ya_hfs_b_behave15")],1,
        function(x){sum(x)})
# HFS worry
df$c_hfs_worry_total <- 
  apply(df[,which(colnames(df)=="c_hfs_worry11"):
                  which(colnames(df)=="c_hfs_worry25")],1,
        function(x){sum(x)})
df$ya_hfs_worry_total <- 
  apply(df[,which(colnames(df)=="ya_hfs_b_worry16"):
                  which(colnames(df)=="ya_hfs_b_worry33")],1,
        function(x){sum(x)})
# Add 1 month variables, select relevant columns
df <- left_join(df,data %>% 
                  filter(gyl_timepoint.factor == "Month 1/ Training F/U") %>%
                  mutate(m1_sensor_wear = sensor_wear,
                         m1_time_am = time_am,
                         m1_tir = sensor_70_180) %>%
                  select(record_id,m1_sensor_wear,m1_time_am,m1_tir),
                by = "record_id") %>%
  select(record_id,am_final,hba1c,c_paid_total,ya_paid_total,
         c_hfs_behave_total,ya_hfs_behave_total,
         c_hfs_worry_total,ya_hfs_worry_total,
         m1_sensor_wear,m1_time_am,m1_tir,
         demographics_t1d_duration,demographics_age,
         demographics_sex.factor,demographics_insurance.factor,
         demographics_race.factor,demographics_ethnicity.factor,
         demographics_cgmhx.factor,demographics_pumphx.factor)
# Binary outcome
df$success <- as.factor(ifelse(df$am_final >= 60,1,0))
levels(df$success) <- c("Failure","Success")
# Categorical variables
df$demographics_age <- cut(df$demographics_age,c(5,13,18,Inf),right = T,
                           labels = c("6 - 13","14 - 18","18+"))
levels(df$demographics_race.factor) = 
  c("Non-white","Non-white","Non-white","Non-white","White","Non-white","Non-white")
levels(df$demographics_cgmhx.factor) = 
  c("<= 6 months","<= 6 months","6+ months","6+ months","6+ months","6+ months",
    "<= 6 months")
levels(df$demographics_pumphx.factor) = 
  c("<= 6 months","<= 6 months","6+ months","6+ months","6+ months","6+ months",
    "<= 6 months")
```

# Model selection

## Lasso

The lasso [1] is a shrinkage method of variable selection, similar to ridge regression. Shrinkage methods impose a penalty on regression coefficients, causing unimportant variables go to 0. The advantage of this approach is that "shrinkage methods are more continuous, and don’t suffer as much from high variability" [2] compared to discrete processes like backwards selection. 

The lasso solves this equation:

![](/Users/timvigers/GitHub/BDC-Code/Greg Forlenza/JDRF/lasso.png)

but basically the only thing you need to understand is that the parameter $\lambda$ controls the amount of shrinkage applied. The higher $\lambda$ is, the more aggressively the coefficients are shrunk. So, it's important to find the optimal $\lambda$ value that results in an interpretable model without too many variables, but with good prediction error compared to the full model. 

Luckily, the glmnet package [3] does pretty much all the work for us! It partitions the data set into 10 equal sub-samples, reserves one for validation and uses the remaining 9 to build the model. This is repeated 10 times so that each subset is used to validate the model once. Within each "fold," multiple values of $\lambda$ are tested. Then, the average error and standard deviation of the error are computed over the folds. Finally, it picks the largest value of $\lambda$ (i.e. the smallest model) such that the error is within one SE of the minimum error. 

### Lasso issues

Using the lasso for model selection requires complete data, and the survey variables have a lot of missing data. The sample size of YA participants is too small to use the lasso, but none of the surveys are associated with the outcome based on simple logistic models of the form:

$$
logit(success) = \beta_0+\beta_1*paid+\beta_2*worry+\beta_3*behave + \epsilon
$$

Because of all this, surveys were excluded from the lasso model selection, in order to keep the data in one cohort and to avoid missing data problems.

### Without interaction terms

```{r without interact,echo=FALSE,warning=FALSE}
# Remove surveys
lasso <- df %>% select(-ya_paid_total,-ya_hfs_behave_total,-ya_hfs_worry_total,
                       -c_paid_total,-c_hfs_behave_total,-c_hfs_worry_total)
# Lasso
# Make model matrix and outcome vector
form <- as.formula("success ~ hba1c + m1_sensor_wear + m1_time_am + m1_tir + 
demographics_t1d_duration + demographics_age + demographics_sex.factor + 
demographics_insurance.factor + demographics_race.factor + 
demographics_ethnicity.factor + demographics_cgmhx.factor + 
demographics_pumphx.factor")
cc <- lasso[complete.cases(lasso),]
x <- model.matrix(form,cc)[,-1]
y <- cc$success
# Fit
fit <- glmnet(x,y,family = "binomial")
plot(fit,xvar = "lambda")
# Cross validation for lambda
cv.fit <- cv.glmnet(x, y, alpha=1, family = "binomial")
coef(cv.fit)
```
As lambda increases, the coefficients are all shrunk to 0. In the table above, the numbers themselves are not important. What matters is whether or not a coefficient was shrunk to 0 or not. The same applies to the lasso with interaction terms included.

### With interaction terms

Because sensor wear and time in automode at month 1 are correlated, only sensor wear was included in further model selection.

```{r with interact,echo=FALSE,warning=FALSE}
# Lasso
# Make model matrix and outcome vector
form <- as.formula("success ~ demographics_age*hba1c + 
demographics_age*m1_sensor_wear + demographics_age*m1_tir + 
demographics_age*demographics_sex.factor + 
demographics_age*demographics_ethnicity.factor + 
demographics_age*demographics_pumphx.factor")
cc <- lasso[complete.cases(lasso),]
x <- model.matrix(form,cc)[,-1]
y <- cc$success
# Fit
fit <- glmnet(x,y,family = "binomial")
plot(fit,xvar = "lambda")
# Cross validation for lambda
cv.fit <- cv.glmnet(x, y, alpha=1, family = "binomial")
coef(cv.fit)
```

## Re-fitting the model

After applying the lasso to determine which variables are kept in the model, we re-fit a standard logistic regression (because the lasso estimates are biased by the shrinkage parameter).

### Issues

Unfortunately, several categorical variables selected by the lasso caused fitted probabilities numerically 0 or 1. In other words, there are levels of the interaction terms where there are either no successes or no failures. I assumed that the lasso would somehow pick up on this and would shrink all the categorical variables coefficients to 0, but this was clearly not the case (and in retrospect a silly assumption).

Also, there is unfortunately not enough variability in pump history or ethnicity to get accurate estimates, since 73/90 (~ 80%) participants are not Hispanic with 6+ months of pump history. See the large coefficients and standard errors in the model summary below.

```{r log model,echo=FALSE,results='asis'}
full_model = as.formula("success ~ demographics_ethnicity.factor + 
interaction(demographics_age,demographics_sex.factor) + 
interaction(demographics_age,demographics_pumphx.factor)")
full_mod = glm(full_model,family = "binomial",df)

t = tableby(full_model,df)
kable(summary(t),caption = "Group Ns")
```

```{r echo=FALSE}
no_int_model = as.formula("success ~ hba1c + m1_sensor_wear + m1_tir + 
demographics_ethnicity.factor + demographics_age + demographics_sex.factor + 
demographics_pumphx.factor")

no_int_mod = glm(no_int_model,family = "binomial",df)
kable(summary(no_int_mod)$coefficients,caption = "Bad model summary")
```

The tables above are simply to demonstrate how these issues look in the variable counts and model results.

## Results

After all that, the results below are what we'll present in the manuscript.

### Table 1: Descriptive Characteristics

```{r table 1,echo=FALSE,results='asis'}
t1_form <- paste(colnames(df)[2:ncol(df)],collapse = "+")
t1 <- tableby(as.formula(paste("success~",t1_form)),data = df)
summary(t1,labelTranslations = 
          list(am_final = "AM Use at Final Visit",hba1c = "Baseline HbA1c",
               c_paid_total = "PAID PEDS Score",
               ya_paid_total = "YA PAID Score",
               c_hfs_behave_total = "Child HFS Behave Score",
               ya_hfs_behave_total = "YA HFS Behave Score",
               c_hfs_worry_total = "Child HFS Worry Score",
               ya_hfs_worry_total = "YA HFS Worry Score",
               m1_sensor_wear = "M1 Sensor Wear",m1_time_am = "M1 Time in AM",
               m1_tir = "M1 TIR",demographics_t1d_duration = "T1D Duration",
               demographics_age = "Age Group",demographics_sex.factor = "Sex",
               demographics_insurance.factor = "Insurance",
               demographics_race.factor = "Race",
               demographics_ethnicity.factor = "Ethnicity",
               demographics_cgmhx.factor = "CGM Hx.",
               demographics_pumphx.factor = "Pump Hx."))
```

### Final model

```{r final model,echo=FALSE}
final_model = as.formula("success ~ scale(hba1c,scale=F) + 
                         scale(m1_sensor_wear,scale=F) + scale(m1_tir,scale=F) + 
                         demographics_age + demographics_sex.factor")

final_mod = glm(final_model,family = "binomial",df)
t = broom::tidy(final_mod,conf.int = T)
t$term[2:nrow(t)] = c("Baseline HbA1c","M1 Sensor Wear","M1 TIR",
                      "Baseline Age 14 - 18","Baseline Age 18+","Male")
kable(t)
```

The coefficients above must be exponentiated in order to interpret them. So, the interpretation is that for each 1-unit increase in sensor wear at month 1, the odds of success increase $e^\beta$ = `r exp(t$estimate[t$term == "M1 Sensor Wear"])` times. Continuous variables have been mean-centered, so the intercept is interpreted as the average odds of success for a participant with average values of continuous variables and 0 (reference group) for all categorical.

## Figures

### ROC of final model

```{r echo=FALSE}
r = ROC(form = final_model,data = df,MX=F,MI=F,PV=F,plot = "ROC")
```

### HbA1c by age group

```{r echo=FALSE}
ggplot(df,aes(x=demographics_age,y=hba1c))+geom_boxplot() + 
  theme_bw() + xlab("Age Group") + ylab("HbA1c (%)")
```

# References

1. 	Tibshirani R. Regression Shrinkage and Selection Via the Lasso. J R Stat Soc Ser B Methodol. 1996;58(1):267-288. doi:10.1111/j.2517-6161.1996.tb02080.x

2. 	Hastie T, Tibshirani R, Friedman JH. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. 2nd ed. Springer; 2009

3. 	Friedman J, Hastie T, Tibshirani R. Regularization Paths for Generalized Linear Models via Coordinate Descent. J Stat Softw. 2010;33(1). doi:10.18637/jss.v033.i01
