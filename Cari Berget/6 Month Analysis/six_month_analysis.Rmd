---
title: "6 Month Analysis"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tools)
library(tableone)
library(nlme)
library(knitr)
library(tidyverse)
# Check OS and alter file path accordingly.
if (.Platform$OS.type == "windows") {pathstart <- "//ucdenver.pvt/"} else if (.Platform$OS.type == "unix"){pathstart <- "/Volumes/"}
```

```{r echo=FALSE,warning=FALSE,eval=FALSE}
# Read in glycemic data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_GlycemicDATA_2019-01-07_.csv")
glycemicdata <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Format dates
datecols <- c("demographics_consent","demographics_dob","demographics_diabetesdx","automode_start",
              "hba1c_date_b","hba1c_date_m1","t1_date_m1","hba1c_date_t1","t1_date","hba1c_date_t2",
              "t2_date")
glycemicdata[,datecols] <- lapply(glycemicdata[,datecols], function(x) mdy(x,tz = "MST"))
```

```{r echo=FALSE, eval=FALSE}
# Re-assign visit dates based on Cari's decisions. CSV file manually edited for easier import.
# Notes:
# 1. Cari is double checking #14 dates, others in CSV file are correct. 
# 2. Baseline A1c can be 2 weeks after AM start.
# 3. "Date Questions.csv" manually edited for easier R import.
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/Date Questions.csv")
correct.dates <- read.csv(filename,stringsAsFactors = F,na.strings = c("","none"))
correct.dates[,2:5] <- lapply(correct.dates[,2:5],function(x) mdy(x,tz = "MST"))
# Split into separate data frames, rename columns.
m1cols <- c(grep("m1_",colnames(glycemicdata)),grep("_m1",colnames(glycemicdata)))
original.m1 <- glycemicdata[,c(1,m1cols)]
colnames(original.m1) <- sub("_m1","",colnames(original.m1))
colnames(original.m1) <- sub("t1_","",colnames(original.m1))
# T1
t1cols <- c(grep("t1_",colnames(glycemicdata)),grep("_t1",colnames(glycemicdata)))
original.t1 <- glycemicdata[,c(1,t1cols)]
colnames(original.t1) <- sub("t1_","",colnames(original.t1))
colnames(original.t1) <- sub("_t1","",colnames(original.t1))
# T2
t2cols <- c(grep("t2_",colnames(glycemicdata)),grep("_t2",colnames(glycemicdata)))
original.t2 <- glycemicdata[,c(1,t2cols)]
colnames(original.t2) <- sub("t2_","",colnames(original.t2))
colnames(original.t2) <- sub("_t2","",colnames(original.t2))
# Define variables of interest
vars <- c("hba1c","am_time","mm_time","sensor_wear","sensor_u54","sensor_55_69",
          "sensor_70_180","sensor_181_250","sensor_g250","mean_sg","sd",
          "bg_checks","calibrations","tdd","basal","bolus","amexit",
          "amexit_day","amexit_hyper","amexit_hypo","amexit_manual","amexit_other")
# Combine, remove duplicates and melt
allcols <- c("record_id","date",vars)
alldat <- rbind(original.m1[,allcols],original.t1[,allcols],original.t2[,allcols])
alldat <- alldat[which(duplicated(alldat[,c("record_id","date")])==F),]
alldat <- melt(alldat,id.vars = c("record_id","date"))
# Spread
alldat <- spread(alldat,key = variable,value = value)
# Get corrected M1 data
m1 <- correct.dates[,c("record_id","correct.m1.date")]
colnames(m1) <- c("record_id","date")
m1 <- left_join(m1,alldat,by = c("record_id","date"))
m1$tpoint <- "M1"
# Get corrected T1 data
t1 <- correct.dates[,c("record_id","correct.t1.date")]
colnames(t1) <- c("record_id","date")
t1 <- left_join(t1,alldat,by = c("record_id","date"))
t1$tpoint <- "T1"
# Get corrected T2 data
t2 <- correct.dates[,c("record_id","correct.t2.date")]
colnames(t2) <- c("record_id","date")
t2 <- left_join(t2,alldat,by = c("record_id","date"))
t2$tpoint <- "T2"
# Merge M1, T1, and T2
alldat <- bind_rows(m1,t1,t2)
alldat <- alldat[order(alldat$record_id),]
# Add autmode start and calculate days
alldat <- merge(alldat,glycemicdata[,c("record_id","automode_start")])
alldat$days <- as.numeric(difftime(alldat$date, alldat$automode_start,units = "days"))
# Import baseline data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_BaselineGlycemicData_14JAN2019.csv")
baseline <- read.csv(filename)
colnames(baseline) <- sub("_b","",colnames(baseline))
baseline$tpoint <- "B"
# Merge everything, sort
alldat <- bind_rows(alldat,baseline)
alldat <- alldat[order(alldat$record_id),]
# Make record ID and timepoint factor
alldat$record_id <- as.factor(alldat$record_id)
alldat$tpoint <- as.factor(alldat$tpoint)
# Get baseline A1c
alldat$hba1c[alldat$tpoint == "B"] <- glycemicdata$hba1c_baseline
# Notes

# List of manual data changes
# Renames columns:
# sensor_54_69_m1 to sensor_55_69_m1
# baseline data sensor_54_69 to sensor_55_69
# all "amexits" to "amexit"

# Additional data notes
# Using a strict 3 month +/- 45 days window would have resulted in the loss of quite a bit of data, so visit dates were manually re-classified by Cari Berget. 
# The cleaned data was sent to Cari Berget due to several concerning outliers. She corrected the data and sent it back, so this chunk of code no longer needs to run. The cleaned data from Cari is just imported instead.  
```

```{r echo=FALSE,eval=FALSE}
# Read in survey data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChildSurvey_DATA_2019-01-07_.csv")
child <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Column names for each survey
b_cols_paid <- paste0("c_paid",seq(1:20))
t1_cols_paid <- paste0(b_cols_paid,"_t1")
t2_cols_paid <- paste0(b_cols_paid,"_t2")
b_cols_maintain <- paste0("c_hfs_behave",c(3,4,7))
t1_cols_maintain <- paste0(b_cols_maintain,"_t1")
t2_cols_maintain <- paste0(b_cols_maintain,"_t2")
b_cols_helpless <- paste0("c_hfs_worry",c(11,12,13,14,16,18,19,22,23))
t1_cols_helpless <- paste0(b_cols_helpless,"_t1")
t2_cols_helpless <- paste0(b_cols_helpless,"_t2")
b_cols_worry <- paste0("c_hfs_worry",c(15,17,20,21,25))
t1_cols_worry <- paste0(b_cols_worry,"_t1")
t2_cols_worry <- paste0(b_cols_worry,"_t2")
# Score by timepoint, gather into separate frame
child$B <- apply(child[,b_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
child$T1 <- apply(child[,t1_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
child$T2 <- apply(child[,t2_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
paid <- gather(child[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

child$B <- apply(child[,b_cols_maintain],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_maintain],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_maintain],1,function(x) sum((x - 1)))
maintain <- gather(child[,c("record_id","B","T1","T2")],tpoint, maintain_score, B:T2)

child$B <- apply(child[,b_cols_helpless],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_helpless],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_helpless],1,function(x) sum((x - 1)))
helpless <- gather(child[,c("record_id","B","T1","T2")],tpoint, helpless_score, B:T2)

child$B <- apply(child[,b_cols_worry],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_worry],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_worry],1,function(x) sum((x - 1)))
worry <- gather(child[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys, replace NaN with NA, rename columns.
child_surveys <- plyr::join_all(list(paid,maintain,helpless,worry), by = c("record_id","tpoint"))
child_surveys <- child_surveys[order(child_surveys$record_id),]
child_surveys$paid_score[is.nan(child_surveys$paid_score)] <- NA
colnames(child_surveys) <- c("record_id","tpoint","cpaid_score","cmaintain_score","chelpless_score","cworry_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_child_survey.csv")
write.csv(child_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE,eval=FALSE}
# YA survey scores
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GYoungAdult_SurveyDATA_2019-01-07_.csv")
ya <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Change column names
b_cols_paid <- paste0("ya_paid",seq(1:20),"_base")
t1_cols_paid <- paste0("ya_paid",seq(1:20),"_t1")
t2_cols_paid <- paste0("ya_paid",seq(1:20),"_t2")
b_cols_behavior <- paste0("ya_hfs_behave",1:15,"_b")
t1_cols_behavior <- paste0("ya_hfs_behave",1:15,"_t1")
# Note: manually changed column "ya_hfs_behave9_b_t1_t2" to "ya_hfs_behave9_t2"
t2_cols_behavior <- paste0("ya_hfs_behave",1:15,"_t2")
b_cols_worry <- paste0("ya_hfs_worry",1:18,"_b")
t1_cols_worry <- paste0("ya_hfs_worry",1:18,"_t1")
t2_cols_worry <- paste0("ya_hfs_worry",1:18,"_t2")
# Score by timepoint, gather into separate frame
ya$B <- apply(ya[,b_cols_paid],1,function(x) sum(x) * 1.25)
ya$T1 <- apply(ya[,t1_cols_paid],1,function(x) sum(x) * 1.25)
ya$T2 <- apply(ya[,t2_cols_paid],1,function(x) sum(x) * 1.25)
paid <- gather(ya[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

ya$B <- apply(ya[,b_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
ya$T1 <- apply(ya[,t1_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
ya$T2 <- apply(ya[,t2_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
behavior <- gather(ya[,c("record_id","B","T1","T2")],tpoint, behavior_score, B:T2)

ya$B <- apply(ya[,b_cols_worry],1,function(x) sum((x - 1),na.rm = T))
# Note: manually changed column "ya_hfs_worry8_b_t1" to "ya_hfs_worry8_t1"
ya$T1 <- apply(ya[,t1_cols_worry],1,function(x) sum((x - 1),na.rm = T))
ya$T2 <- apply(ya[,t2_cols_worry],1,function(x) sum((x - 1),na.rm = T))
worry <- gather(ya[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys. Calculate total HFS. Rename columns.
ya_surveys <- plyr::join_all(list(paid,behavior,worry), by = c("record_id","tpoint"))
ya_surveys <- ya_surveys[order(ya_surveys$record_id),]
ya_surveys$total_hfs <- ya_surveys$behavior_score + ya_surveys$worry_score
colnames(ya_surveys) <- c("record_id","tpoint","yapaid_score","yabehavior_score","yaworry_score","yatotal_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_ya_survey.csv")
write.csv(ya_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE,eval=FALSE}
# Parent survey scores
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GParentSurvey_DATA_2019-01-07_.csv")
parent <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Column names for each survey
b_cols_paid <- paste0("p_paid",seq(1:18))
t1_cols_paid <- paste0(b_cols_paid,"_t1")
t2_cols_paid <- paste0(b_cols_paid,"_t2")
b_cols_maintain <- paste0("p_hfs_behave",c(3,4,7))
t1_cols_maintain <- paste0(b_cols_maintain,"_t1")
t2_cols_maintain <- paste0(b_cols_maintain,"_t2")
b_cols_helpless <- paste0("p_hfs_worry",c(12,13,14,15,17,20,23,24,25,26))
t1_cols_helpless <- paste0(b_cols_helpless,"_t1")
t2_cols_helpless <- paste0(b_cols_helpless,"_t2")
b_cols_worry <- paste0("p_hfs_worry",c(16,18,19,21,22))
t1_cols_worry <- paste0(b_cols_worry,"_t1")
t2_cols_worry <- paste0(b_cols_worry,"_t2")
# Score by timepoint, gather into separate frame
parent$B <- apply(parent[,b_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
parent$T1 <- apply(parent[,t1_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
parent$T2 <- apply(parent[,t2_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
paid <- gather(parent[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

parent$B <- apply(parent[,b_cols_maintain],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_maintain],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_maintain],1,function(x) sum((x - 1)))
maintain <- gather(parent[,c("record_id","B","T1","T2")],tpoint, maintain_score, B:T2)

parent$B <- apply(parent[,b_cols_helpless],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_helpless],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_helpless],1,function(x) sum((x - 1)))
helpless <- gather(parent[,c("record_id","B","T1","T2")],tpoint, helpless_score, B:T2)

parent$B <- apply(parent[,b_cols_worry],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_worry],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_worry],1,function(x) sum((x - 1)))
worry <- gather(parent[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys, replace NaN with NA. Rename columns.
parent_surveys <- plyr::join_all(list(paid,maintain,helpless,worry), by = c("record_id","tpoint"))
parent_surveys <- parent_surveys[order(parent_surveys$record_id),]
parent_surveys$paid_score[is.nan(parent_surveys$paid_score)] <- NA
colnames(parent_surveys) <- c("record_id","tpoint","ppaid_score","pmaintain_score","phelpless_score","pworry_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_parent_survey.csv")
write.csv(parent_surveys,file = filename,row.names = F,na = "")
```

# Methods

Linear mixed effects models were used to examine change in HbA1c, problem areas in diabetes (PAID) survey scores, and hypoglycemia fear survey scores over time. Participants without at least 10% automode (AM) use at their first and second visits (T1 and T2) were excluded. 

For HbA1c and PAID pediatric (PAID-PEDS) scores, three models were compared using Aikaike’s Information Criterion to select the best model:

1.	A random intercept model with visit number (baseline, T1, T2) as a categorical time variable.  No adjustment for the baseline value of HbA1c or baseline PAID score.
2.	A random intercept model with visit number as a continuous time variable, without adjustment for baseline.
3.	A random intercept and random slope model, without adjustment for baseline.

For HbA1c , the random intercept model with time treated as a categorical variable was the best model. Originally the models were adjusted for baseline value (as we did for the abstract), but it was decided that this adjustment does not make sense given the question this study wants to answer, in addition to making the model results difficult to interpret.

# Results

```{r echo=FALSE}

```

```{r echo=FALSE}
# Import Cari's cleaned data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_glycemic_data.csv")
alldata <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
# Define variables of interest.
vars <- c("hba1c","am_time","mm_time","sensor_wear","sensor_u54","sensor_55_69",
          "sensor_70_180","sensor_181_250","sensor_g250","mean_sg","sd",
          "bg_checks","calibrations","tdd","basal","bolus","amexit",
          "amexit_day","amexit_hyper","amexit_hypo","amexit_manual","amexit_other")
# Import cleaned, scored survey data.
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_parent_survey.csv")
parent_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F)
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_child_survey.csv")
child_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_ya_survey.csv")
ya_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
# Add survey scores to full data.
alldata <- left_join(alldata,child_survey,by = c("record_id","tpoint"))
alldata <- left_join(alldata,ya_survey,by = c("record_id","tpoint"))
alldata <- full_join(alldata,parent_survey,by = c("record_id","tpoint"))
# Order, add baseline A1c, remove AM time < 10% (at T1 or T2)
alldata <- alldata %>%
  arrange(record_id,tpoint) %>%
  group_by(record_id) %>%
  mutate(baseline_a1c = hba1c[1]) %>%
  mutate(baseline_cpaid = cpaid_score[1]) %>%
  mutate(baseline_cmaintain = cmaintain_score[1]) %>%
  mutate(baseline_chelpless = chelpless_score[1]) %>%
  mutate(baseline_cworry = cworry_score[1]) %>%
  mutate(baseline_yapaid = yapaid_score[1]) %>%
  mutate(baseline_yabehavior = yabehavior_score[1]) %>%
  mutate(baseline_yaworry = yaworry_score[1]) %>%
  mutate(baseline_yatotal = yatotal_score[1]) %>%
  mutate(baseline_ppaid = ppaid_score[1]) %>%
  mutate(baseline_pmaintain = pmaintain_score[1]) %>%
  mutate(baseline_phelpless = phelpless_score[1]) %>%
  mutate(baseline_pworry = pworry_score[1]) %>%
  filter(!((tpoint == "T1" | tpoint == "T2") & am_time < 10))
alldata$tpoint <- as.factor(alldata$tpoint)
alldata$record_id <- as.factor(alldata$record_id)
```

## Figure 1a: HbA1c by Timepoint, Grouped by Clinical HbA1c Cutoffs at Baseline
```{r echo=FALSE,warning=FALSE,dpi=600}
# Remove M1, group by clinical A1c cutoffs and tertiles at baseline
tertiles <- as.numeric(quantile(as.numeric(alldata$hba1c[which(alldata$tpoint == "B")]),na.rm = T,probs = seq(0, 1, (1/3))))
data_no_m1 <- alldata %>%
  filter(tpoint != "M1") %>%
  mutate(hba1c_tertiles = cut(baseline_a1c,breaks = tertiles)) %>%
  mutate(hba1c_clinical = cut(baseline_a1c,breaks = c(0,7.5,9.0,Inf)))
# By clinical groups
a1c_plot_clin <- 
  ggplot(data_no_m1,aes_string(x = "tpoint",y = "hba1c",group = "record_id")) + 
  geom_line(size = 0.2,aes(color = hba1c_clinical)) +
  xlab("Timepoint") + 
  ylab("HbA1c (%)") + 
  theme(legend.title=element_blank())
a1c_plot_clin
```

## Figure 1b: HbA1c by Timepoint, Grouped by HbA1c Tertiles at Baseline
```{r echo=FALSE,warning=FALSE,dpi=600}
# By tertiles
a1c_plot_tert <- 
  ggplot(data_no_m1,aes_string(x = "tpoint",y = "hba1c",group = "record_id")) + 
  geom_line(size = 0.2,aes(color = hba1c_tertiles)) +
  xlab("Timepoint") + 
  ylab("HbA1c (%)") +
  theme(legend.title=element_blank())
a1c_plot_tert
```

```{r echo=FALSE, include=FALSE}
# A1c mixed models
a1c_mod <- lme(hba1c ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
a1c_mod_cont <- lme(hba1c ~ as.numeric(tpoint),random=~1|record_id,data = data_no_m1,na.action = na.omit) # Categorical is better
# Means model
a1c_mod_means <- lme(hba1c ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

In the above figures, a square bracket indicates that the number is included in the range. So (0,7.5] means that baseline HbA1c was less than or equal to 7.5.

## Table 2: A1c Mixed Models
```{r echo=FALSE}
kable(summary(a1c_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(a1c_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(a1c_mod_means)$tTable,caption = "Timepoint Means")
```

### Mixed model interpretation
The interpretation of fixed effects for a mixed model is the same as the interpretation for a simple linear model. The first table shows the difference between baseline and T1 and baseline and T2. The intercept is the mean at baseline, and the values for each timepoint are the average difference from baseline. So, on average HbA1c decreased by 0.48 from baseline to T1 and by 0.28 from baseline to T2. Both of these differences were statistically significant at the 0.05 level.

The type 3 tests of fixed effects show that timepoint overall was significant,meaning that there were significant changes in A1c over time after adjusting for baseline A1c.

The third table simply shows the average HbA1c at each timepoint. The p values in this table indicate whether the mean HbA1c was significantly different from 0, so probably are not worth reporting.  

<!-- ## Figure 2: PAID-PEDS by Timepoint -->
```{r echo=FALSE,warning=FALSE,dpi=600,eval=FALSE}
paid_peds_plot <- 
  ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = "cpaid_score",group = "record_id")) + 
  geom_line(size = 0.2) +
  xlab("Timepoint") + 
  ylab("PAID-PEDS Score")
paid_peds_plot
```

```{r echo=FALSE,include=FALSE,eval=FALSE}
# PAID-PEDS mixed models
paidc_mod_reduced <- lme(cpaid_score ~ tpoint,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)

paidc_mod_adj <- lme(cpaid_score ~ tpoint + baseline_cpaid,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
AIC(paidc_mod_reduced)
AIC(paidc_mod_adj) # adjusted is better by AIC
# Continous time
paidc_reduced_cont <- lme(cpaid_score ~ as.numeric(tpoint),random=~1|record_id,data = alldata,na.action = na.omit)
paidc_adj_cont <- lme(cpaid_score ~ as.numeric(tpoint) + baseline_cpaid,random=~1|record_id,data = alldata,na.action = na.omit)
AIC(paidc_reduced_cont)
AIC(paidc_adj_cont) # Adjusted model with categorical time still the best.
# Random slope
paidc_mod_adj_rs <- lme(cpaid_score ~ as.numeric(tpoint) + baseline_cpaid,random=~1|record_id/tpoint,data = alldata,na.action = na.omit)
AIC(paidc_mod_adj_rs) # Adjusted with random intercept still the best, report that.
# Means model
paidc_mod_adj_means <- lme(cpaid_score ~ tpoint + baseline_cpaid-1,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
```

<!-- ## Table 3: PAID-PEDS Mixed Models -->
```{r echo=FALSE,eval=FALSE}
kable(summary(paidc_mod_adj_means)$tTable,caption = "Fixed Effects")
kable(anova.lme(paidc_mod_adj_means),caption = "Type 3 Tests of Fixed Effects")
```

<!-- ## Figure 3: PAID-YA by Timepoint -->
```{r echo=FALSE,warning=FALSE,dpi=600,eval=FALSE}
paid_ya_plot <- 
  ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = "yapaid_score",group = "record_id")) + 
  geom_line(size = 0.2) +
  xlab("Timepoint") + 
  ylab("PAID-YA Score")
paid_ya_plot
```

```{r echo=FALSE,include=FALSE,eval=FALSE}
# PAID-YA mixed model (same as peds model)
paidya_mod_adj <- lme(yapaid_score ~ tpoint + baseline_yapaid,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
# Means
paidya_mod_adj_means <- lme(yapaid_score ~ tpoint + baseline_yapaid-1,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
```

<!-- ## Table 4: PAID-YA Mixed Models -->
```{r echo=FALSE,eval=FALSE}
kable(summary(paidya_mod_adj_means)$tTable,caption = "Fixed Effects")
kable(anova.lme(paidya_mod_adj_means),caption = "Type 3 Tests of Fixed Effects")
```

<!-- ## Figure 4: PAID-PR by Timepoint -->
```{r echo=FALSE,warning=FALSE,dpi=600,eval=FALSE}
paid_p_plot <-
  ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = "ppaid_score",group = "record_id")) +
  geom_line(size = 0.2) +
  xlab("Timepoint") +
  ylab("PAID-PR Score")
paid_p_plot
```

```{r echo=FALSE,include=FALSE,eval=FALSE}
# PAID-YA mixed model (same as peds model)
paidpr_mod_adj <- lme(ppaid_score ~ tpoint + baseline_ppaid,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
# Means
paidpr_mod_adj_means <- lme(ppaid_score ~ tpoint + baseline_ppaid-1,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
```

<!-- ## Table 5: PAID-PR Mixed Models -->
```{r echo=FALSE,eval=FALSE}
kable(summary(paidpr_mod_adj_means)$tTable,caption = "Fixed Effects")
kable(anova.lme(paidpr_mod_adj_means),caption = "Type 3 Tests of Fixed Effects")
```

<!-- ## HFS-PEDS -->
```{r echo=FALSE,warning=FALSE,results="asis",dpi=600,eval=FALSE}
vars <- c("cmaintain_score","chelpless_score","cworry_score")
for (v in vars) {
  base <- sub("_score","",v)
  label <- sub("c*","",base)
  plot <- ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = v,group = "record_id")) + 
    geom_line(size = 0.2) +
    xlab("Timepoint") + 
    ylab(label) +
    ggtitle(paste(toTitleCase(label),"Score by Timepoint"))+
    theme(plot.title = element_text(hjust = 0.5))
  print(plot)
  form <- as.formula(paste(v,"~","tpoint + ",paste0("baseline_",base,"-1")))
  mod_adj <- lme(form,
                 random=~1|record_id,
                 data = alldata,na.action = na.omit)
  print(kable(summary(mod_adj)$tTable,caption = "Fixed Effects"))
  cat("\n")
  print(kable(anova.lme(mod_adj),caption = "Type 3 Tests of Fixed Effects"))
  cat("\n")
}
```

<!-- ## HFS-YA -->
```{r echo=FALSE,warning=FALSE,results="asis",dpi=600,eval=FALSE}
vars <- c("yabehavior_score","yaworry_score","yatotal_score")
for (v in vars) {
  base <- sub("_score","",v)
  label <- sub("ya*","",base)
  plot <- ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = v,group = "record_id")) + 
    geom_line(size = 0.2) +
    xlab("Timepoint") + 
    ylab(label) +
    ggtitle(paste(toTitleCase(label),"by Timepoint")) +
    theme(plot.title = element_text(hjust = 0.5))
  print(plot)
  form <- as.formula(paste(v,"~","tpoint + ",paste0("baseline_",base,"-1")))
  mod_adj <- lme(form,
                 random=~1|record_id,
                 data = alldata,na.action = na.omit)
  print(kable(summary(mod_adj)$tTable,caption = "Fixed Effects"))
  cat("\n")
  print(kable(anova.lme(mod_adj),caption = "Type 3 Tests of Fixed Effects"))
  cat("\n")
}
```

<!-- ## HFS-PR -->
```{r echo=FALSE,warning=FALSE,results="asis",dpi=600,eval=FALSE}
vars <- c("pmaintain_score","phelpless_score","pworry_score")
for (v in vars) {
  base <- sub("_score","",v)
  label <- sub("p*","",base)
  plot <- ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = v,group = "record_id")) + 
    geom_line(size = 0.2) +
    xlab("Timepoint") + 
    ylab(label) +
    ggtitle(paste(toTitleCase(label),"by Timepoint")) +
    theme(plot.title = element_text(hjust = 0.5))
  print(plot)
  form <- as.formula(paste(v,"~","tpoint + ",paste0("baseline_",base,"-1")))
  mod_adj <- lme(form,
                 random=~1|record_id,
                 data = alldata,na.action = na.omit)
  print(kable(summary(mod_adj)$tTable,caption = "Fixed Effects"))
  cat("\n")
  print(kable(anova.lme(mod_adj),caption = "Type 3 Tests of Fixed Effects"))
  cat("\n")
}
```

```{r eval=FALSE,include=FALSE}
# General notes
# During 4/12/19 meeting we decided that adjusting the models for baseline value
# doesn't really answer the scientific question. Also Cari would like to compare
# baseline to 3 month and 6 month. Month 1 A1c overlaps too much with baseline. 
# Briggs also requested new figures grouped by glycemic control (7.5, 9.0, and 
# above, plus tertiles/quartiles).
```