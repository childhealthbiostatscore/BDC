---
title: "6 Month Analysis"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tableone)
library(nlme)
library(knitr)
library(tidyverse)
# Check OS and alter file path accordingly.
if (.Platform$OS.type == "windows") {pathstart <- "//ucdenver.pvt/"} else if (.Platform$OS.type == "unix"){pathstart <- "/Volumes/"}
```

```{r echo=FALSE,warning=FALSE,eval=FALSE}
# Read in glycemic data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_GlycemicDATA_2019-01-07_.csv")
glycemicdata <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Format dates
datecols <- c("demographics_consent","demographics_dob","demographics_diabetesdx","automode_start",
              "hba1c_date_b","hba1c_date_m1","t1_date_m1","hba1c_date_t1","t1_date","hba1c_date_t2",
              "t2_date")
glycemicdata[,datecols] <- lapply(glycemicdata[,datecols], function(x) mdy(x,tz = "MST"))
```

```{r echo=FALSE, eval=FALSE}
# Re-assign visit dates based on Cari's decisions. CSV file manually edited for easier import.
# Notes:
# 1. Cari is double checking #14 dates, others in CSV file are correct. 
# 2. Baseline A1c can be 2 weeks after AM start.
# 3. "Date Questions.csv" manually edited for easier R import.
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/Date Questions.csv")
correct.dates <- read.csv(filename,stringsAsFactors = F,na.strings = c("","none"))
correct.dates[,2:5] <- lapply(correct.dates[,2:5],function(x) mdy(x,tz = "MST"))
# Split into separate data frames, rename columns.
m1cols <- c(grep("m1_",colnames(glycemicdata)),grep("_m1",colnames(glycemicdata)))
original.m1 <- glycemicdata[,c(1,m1cols)]
colnames(original.m1) <- sub("_m1","",colnames(original.m1))
colnames(original.m1) <- sub("t1_","",colnames(original.m1))
# T1
t1cols <- c(grep("t1_",colnames(glycemicdata)),grep("_t1",colnames(glycemicdata)))
original.t1 <- glycemicdata[,c(1,t1cols)]
colnames(original.t1) <- sub("t1_","",colnames(original.t1))
colnames(original.t1) <- sub("_t1","",colnames(original.t1))
# T2
t2cols <- c(grep("t2_",colnames(glycemicdata)),grep("_t2",colnames(glycemicdata)))
original.t2 <- glycemicdata[,c(1,t2cols)]
colnames(original.t2) <- sub("t2_","",colnames(original.t2))
colnames(original.t2) <- sub("_t2","",colnames(original.t2))
# Define variables of interest
vars <- c("hba1c","am_time","mm_time","sensor_wear","sensor_u54","sensor_55_69",
          "sensor_70_180","sensor_181_250","sensor_g250","mean_sg","sd",
          "bg_checks","calibrations","tdd","basal","bolus","amexit",
          "amexit_day","amexit_hyper","amexit_hypo","amexit_manual","amexit_other")
# Combine, remove duplicates and melt
allcols <- c("record_id","date",vars)
alldat <- rbind(original.m1[,allcols],original.t1[,allcols],original.t2[,allcols])
alldat <- alldat[which(duplicated(alldat[,c("record_id","date")])==F),]
alldat <- melt(alldat,id.vars = c("record_id","date"))
# Spread
alldat <- spread(alldat,key = variable,value = value)
# Get corrected M1 data
m1 <- correct.dates[,c("record_id","correct.m1.date")]
colnames(m1) <- c("record_id","date")
m1 <- left_join(m1,alldat,by = c("record_id","date"))
m1$tpoint <- "M1"
# Get corrected T1 data
t1 <- correct.dates[,c("record_id","correct.t1.date")]
colnames(t1) <- c("record_id","date")
t1 <- left_join(t1,alldat,by = c("record_id","date"))
t1$tpoint <- "T1"
# Get corrected T2 data
t2 <- correct.dates[,c("record_id","correct.t2.date")]
colnames(t2) <- c("record_id","date")
t2 <- left_join(t2,alldat,by = c("record_id","date"))
t2$tpoint <- "T2"
# Merge M1, T1, and T2
alldat <- bind_rows(m1,t1,t2)
alldat <- alldat[order(alldat$record_id),]
# Add autmode start and calculate days
alldat <- merge(alldat,glycemicdata[,c("record_id","automode_start")])
alldat$days <- as.numeric(difftime(alldat$date, alldat$automode_start,units = "days"))
# Import baseline data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_BaselineGlycemicData_14JAN2019.csv")
baseline <- read.csv(filename)
colnames(baseline) <- sub("_b","",colnames(baseline))
baseline$tpoint <- "B"
# Merge everything, sort
alldat <- bind_rows(alldat,baseline)
alldat <- alldat[order(alldat$record_id),]
# Make record ID and timepoint factor
alldat$record_id <- as.factor(alldat$record_id)
alldat$tpoint <- as.factor(alldat$tpoint)
# Get baseline A1c
alldat$hba1c[alldat$tpoint == "B"] <- glycemicdata$hba1c_baseline
# Notes

# List of manual data changes
# Renames columns:
# sensor_54_69_m1 to sensor_55_69_m1
# baseline data sensor_54_69 to sensor_55_69
# all "amexits" to "amexit"

# Additional data notes
# Using a strict 3 month +/- 45 days window would have resulted in the loss of quite a bit of data, so visit dates were manually re-classified by Cari Berget. 
# The cleaned data was sent to Cari Berget due to several concerning outliers. She corrected the data and sent it back, so this chunk of code no longer needs to run. The cleaned data from Cari is just imported instead.  
```

```{r echo=FALSE,eval=FALSE}
# Read in survey data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChildSurvey_DATA_2019-01-07_.csv")
child <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Column names for each survey
b_cols_paid <- paste0("c_paid",seq(1:20))
t1_cols_paid <- paste0(b_cols_paid,"_t1")
t2_cols_paid <- paste0(b_cols_paid,"_t2")
b_cols_maintain <- paste0("c_hfs_behave",c(3,4,7))
t1_cols_maintain <- paste0(b_cols_maintain,"_t1")
t2_cols_maintain <- paste0(b_cols_maintain,"_t2")
b_cols_helpless <- paste0("c_hfs_worry",c(11,12,13,14,16,18,19,22,23))
t1_cols_helpless <- paste0(b_cols_helpless,"_t1")
t2_cols_helpless <- paste0(b_cols_helpless,"_t2")
b_cols_worry <- paste0("c_hfs_worry",c(15,17,20,21,25))
t1_cols_worry <- paste0(b_cols_worry,"_t1")
t2_cols_worry <- paste0(b_cols_worry,"_t2")
# Score by timepoint, gather into separate frame
child$B <- apply(child[,b_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
child$T1 <- apply(child[,t1_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
child$T2 <- apply(child[,t2_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
paid <- gather(child[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

child$B <- apply(child[,b_cols_maintain],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_maintain],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_maintain],1,function(x) sum((x - 1)))
maintain <- gather(child[,c("record_id","B","T1","T2")],tpoint, maintain_score, B:T2)

child$B <- apply(child[,b_cols_helpless],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_helpless],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_helpless],1,function(x) sum((x - 1)))
helpless <- gather(child[,c("record_id","B","T1","T2")],tpoint, helpless_score, B:T2)

child$B <- apply(child[,b_cols_worry],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_worry],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_worry],1,function(x) sum((x - 1)))
worry <- gather(child[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys, replace NaN with NA, rename columns.
child_surveys <- plyr::join_all(list(paid,maintain,helpless,worry), by = c("record_id","tpoint"))
child_surveys <- child_surveys[order(child_surveys$record_id),]
child_surveys$paid_score[is.nan(child_surveys$paid_score)] <- NA
colnames(child_surveys) <- c("record_id","tpoint","cpaid_score","cmaintain_score","chelpless_score","cworry_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_child_survey.csv")
write.csv(child_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE,eval=FALSE}
# YA survey scores
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GYoungAdult_SurveyDATA_2019-01-07_.csv")
ya <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Change column names
b_cols_paid <- paste0("ya_paid",seq(1:20),"_base")
t1_cols_paid <- paste0("ya_paid",seq(1:20),"_t1")
t2_cols_paid <- paste0("ya_paid",seq(1:20),"_t2")
b_cols_behavior <- paste0("ya_hfs_behave",1:15,"_b")
t1_cols_behavior <- paste0("ya_hfs_behave",1:15,"_t1")
# Note: manually changed column "ya_hfs_behave9_b_t1_t2" to "ya_hfs_behave9_t2"
t2_cols_behavior <- paste0("ya_hfs_behave",1:15,"_t2")
b_cols_worry <- paste0("ya_hfs_worry",1:18,"_b")
t1_cols_worry <- paste0("ya_hfs_worry",1:18,"_t1")
t2_cols_worry <- paste0("ya_hfs_worry",1:18,"_t2")
# Score by timepoint, gather into separate frame
ya$B <- apply(ya[,b_cols_paid],1,function(x) sum(x) * 1.25)
ya$T1 <- apply(ya[,t1_cols_paid],1,function(x) sum(x) * 1.25)
ya$T2 <- apply(ya[,t2_cols_paid],1,function(x) sum(x) * 1.25)
paid <- gather(ya[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

ya$B <- apply(ya[,b_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
ya$T1 <- apply(ya[,t1_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
ya$T2 <- apply(ya[,t2_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
behavior <- gather(ya[,c("record_id","B","T1","T2")],tpoint, behavior_score, B:T2)

ya$B <- apply(ya[,b_cols_worry],1,function(x) sum((x - 1),na.rm = T))
# Note: manually changed column "ya_hfs_worry8_b_t1" to "ya_hfs_worry8_t1"
ya$T1 <- apply(ya[,t1_cols_worry],1,function(x) sum((x - 1),na.rm = T))
ya$T2 <- apply(ya[,t2_cols_worry],1,function(x) sum((x - 1),na.rm = T))
worry <- gather(ya[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys. Calculate total HFS. Rename columns.
ya_surveys <- plyr::join_all(list(paid,behavior,worry), by = c("record_id","tpoint"))
ya_surveys <- ya_surveys[order(ya_surveys$record_id),]
ya_surveys$total_hfs <- ya_surveys$behavior_score + ya_surveys$worry_score
colnames(ya_surveys) <- c("record_id","tpoint","yapaid_score","yabehavior_score","yaworry_score","yatotal_hfs")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_ya_survey.csv")
write.csv(ya_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE,eval=FALSE}
# Parent survey scores
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GParentSurvey_DATA_2019-01-07_.csv")
parent <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Column names for each survey
b_cols_paid <- paste0("p_paid",seq(1:18))
t1_cols_paid <- paste0(b_cols_paid,"_t1")
t2_cols_paid <- paste0(b_cols_paid,"_t2")
b_cols_maintain <- paste0("p_hfs_behave",c(3,4,7))
t1_cols_maintain <- paste0(b_cols_maintain,"_t1")
t2_cols_maintain <- paste0(b_cols_maintain,"_t2")
b_cols_helpless <- paste0("p_hfs_worry",c(12,13,14,15,17,20,23,24,25,26))
t1_cols_helpless <- paste0(b_cols_helpless,"_t1")
t2_cols_helpless <- paste0(b_cols_helpless,"_t2")
b_cols_worry <- paste0("p_hfs_worry",c(16,18,19,21,22))
t1_cols_worry <- paste0(b_cols_worry,"_t1")
t2_cols_worry <- paste0(b_cols_worry,"_t2")
# Score by timepoint, gather into separate frame
parent$B <- apply(parent[,b_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
parent$T1 <- apply(parent[,t1_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
parent$T2 <- apply(parent[,t2_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
paid <- gather(parent[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

parent$B <- apply(parent[,b_cols_maintain],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_maintain],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_maintain],1,function(x) sum((x - 1)))
maintain <- gather(parent[,c("record_id","B","T1","T2")],tpoint, maintain_score, B:T2)

parent$B <- apply(parent[,b_cols_helpless],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_helpless],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_helpless],1,function(x) sum((x - 1)))
helpless <- gather(parent[,c("record_id","B","T1","T2")],tpoint, helpless_score, B:T2)

parent$B <- apply(parent[,b_cols_worry],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_worry],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_worry],1,function(x) sum((x - 1)))
worry <- gather(parent[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys, replace NaN with NA. Rename columns.
parent_surveys <- plyr::join_all(list(paid,maintain,helpless,worry), by = c("record_id","tpoint"))
parent_surveys <- parent_surveys[order(parent_surveys$record_id),]
parent_surveys$paid_score[is.nan(parent_surveys$paid_score)] <- NA
colnames(parent_surveys) <- c("record_id","tpoint","ppaid_score","pmaintain_score","phelpless_score","pworry_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_parent_survey.csv")
write.csv(parent_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE}
# Import Cari's cleaned data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_glycemic_data.csv")
alldata <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
# Define variables of interest.
vars <- c("hba1c","am_time","mm_time","sensor_wear","sensor_u54","sensor_55_69",
          "sensor_70_180","sensor_181_250","sensor_g250","mean_sg","sd",
          "bg_checks","calibrations","tdd","basal","bolus","amexit",
          "amexit_day","amexit_hyper","amexit_hypo","amexit_manual","amexit_other")
# Import cleaned, scored survey data.
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_parent_survey.csv")
parent_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F)
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_child_survey.csv")
child_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_ya_survey.csv")
ya_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
# Add survey scores to full data.
alldata <- left_join(alldata,child_survey,by = c("record_id","tpoint"))
alldata <- left_join(alldata,ya_survey,by = c("record_id","tpoint"))
alldata <- full_join(alldata,parent_survey,by = c("record_id","tpoint"))
# Order, add baseline A1c, remove AM time < 10% (at T1 or T2)
alldata <- alldata %>%
  arrange(record_id,tpoint) %>%
  group_by(record_id) %>%
  mutate(baseline_a1c = hba1c[1]) %>%
  mutate(baseline_cpaid = cpaid_score[1]) %>%
  mutate(baseline_yapaid = yapaid_score[1]) %>%
  mutate(baseline_ppaid = ppaid_score[1]) %>%
  filter(!((tpoint == "T1" | tpoint == "T2") & am_time < 10))
alldata$tpoint <- as.factor(alldata$tpoint)
alldata$record_id <- as.factor(alldata$record_id)
```

## Figure 1: HbA1c by Timepoint
```{r echo=FALSE,warning=FALSE}
a1c_plot <- ggplot(alldata,aes_string(x = "tpoint",y = "hba1c",group = "record_id")) + 
  geom_line(size = 0.2) +
  xlab("Timepoint") + 
  ylab("HbA1c (%)")
a1c_plot
```

```{r echo=FALSE, include=FALSE}
# A1c mixed models
a1c_mod_reduced <- lme(hba1c ~ tpoint,random=~1|record_id,data = alldata,na.action = na.omit)
a1c_mod_adj <- lme(hba1c ~ tpoint + baseline_a1c,random=~1|record_id,data = alldata,na.action = na.omit) # Best model by AIC - try adding random slope
# Continous time
a1c_mod_reduced_cont <- lme(hba1c ~ as.numeric(tpoint),random=~1|record_id,data = alldata,na.action = na.omit)
a1c_mod_adj_cont <- lme(hba1c ~ as.numeric(tpoint) + baseline_a1c,random=~1|record_id,data = alldata,na.action = na.omit)
# Random slope
a1c_mod_adj_rs <- lme(hba1c ~ as.numeric(tpoint) + baseline_a1c,random=~1|record_id/tpoint,data = alldata,na.action = na.omit) #AIC up slightly, report random intercept
AIC(a1c_mod_adj)
AIC(a1c_mod_adj_rs)
```

## Table 2: A1c Mixed Models
```{r echo=FALSE}
kable(summary(a1c_mod_adj)$tTable,caption = "Fixed Effects")
kable(anova.lme(a1c_mod_adj),caption = "Type 3 Tests of Fixed Effects")
plot(a1c_mod_adj)
qqnorm(a1c_mod_adj)
```

## Figure 2: PAID-PEDS by Timepoint
```{r echo=FALSE,warning=FALSE}
paid_peds_plot <- 
  ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = "cpaid_score",group = "record_id")) + 
  geom_line(size = 0.2) +
  xlab("Timepoint") + 
  ylab("PAID-PEDS Score")
paid_peds_plot
```

```{r echo=FALSE,include=FALSE}
# PAID-PEDS mixed models
paidc_mod_reduced <- lme(cpaid_score ~ tpoint,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)

paidc_mod_adj <- lme(cpaid_score ~ tpoint + baseline_cpaid,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
AIC(paidc_mod_reduced)
AIC(paidc_mod_adj) # adjusted is better by AIC
# Continous time
paidc_reduced_cont <- lme(cpaid_score ~ as.numeric(tpoint),random=~1|record_id,data = alldata,na.action = na.omit)
paidc_adj_cont <- lme(cpaid_score ~ as.numeric(tpoint) + baseline_cpaid,random=~1|record_id,data = alldata,na.action = na.omit)
AIC(paidc_reduced_cont)
AIC(paidc_adj_cont) # Adjusted model with categorical time still the best.
# Random slope
paidc_mod_adj_rs <- lme(cpaid_score ~ as.numeric(tpoint) + baseline_cpaid,random=~1|record_id/tpoint,data = alldata,na.action = na.omit)
AIC(paidc_mod_adj_rs) # Adjusted with random intercept still the best, report that.
```

## Table 3: PAID-PEDS Mixed Models
```{r echo=FALSE}
kable(summary(paidc_mod_adj)$tTable,caption = "Fixed Effects")
kable(anova.lme(paidc_mod_adj),caption = "Type 3 Tests of Fixed Effects")
plot(paidc_mod_adj)
qqnorm(paidc_mod_adj)
# Try coloring by AM time (above and below median)
```

## Figure 3: PAID-YA by Timepoint
```{r echo=FALSE,warning=FALSE}
paid_ya_plot <- 
  ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = "yapaid_score",group = "record_id")) + 
  geom_line(size = 0.2) +
  xlab("Timepoint") + 
  ylab("PAID-YA Score")
paid_ya_plot
```

```{r echo=FALSE,include=FALSE}
# PAID-YA mixed model (same as peds model)
paidya_mod_adj <- lme(yapaid_score ~ tpoint + baseline_yapaid,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
```

## Table 4: PAID-YA Mixed Models
```{r echo=FALSE}
kable(summary(paidya_mod_adj)$tTable,caption = "Fixed Effects")
kable(anova.lme(paidya_mod_adj),caption = "Type 3 Tests of Fixed Effects")
plot(paidya_mod_adj)
qqnorm(paidya_mod_adj)
```

## Figure 4: PAID-PR by Timepoint
```{r echo=FALSE,warning=FALSE}
paid_p_plot <-
  ggplot(alldata[alldata$tpoint != "M1",],aes_string(x = "tpoint",y = "ppaid_score",group = "record_id")) +
  geom_line(size = 0.2) +
  xlab("Timepoint") +
  ylab("PAID-PR Score")
paid_p_plot
```

```{r echo=FALSE,include=FALSE}
# PAID-YA mixed model (same as peds model)
paidpr_mod_adj <- lme(ppaid_score ~ tpoint + baseline_ppaid,
                       random=~1|record_id,
                       data = alldata,na.action = na.omit)
```

## Table 5: PAID-YA Mixed Models
```{r echo=FALSE}
kable(summary(paidpr_mod_adj)$tTable,caption = "Fixed Effects")
kable(anova.lme(paidpr_mod_adj),caption = "Type 3 Tests of Fixed Effects")
plot(paidpr_mod_adj)
qqnorm(paidpr_mod_adj)
```

