---
title: "Polygenic Risk of T1D in Hispanic People"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(lassosum)
library(data.table)
library(methods)
library(magrittr)
library(parallel)
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE)
home_dir = ifelse(.Platform$OS.type != "unix","T:/",
                  "~/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/biobank_analysis/imputed/")
knitr::opts_knit$set(root.dir = home_dir)
```

```{r cache=TRUE,include=FALSE}
# Read in and process the covariates
covariate <- read.delim("p.phen",header = F)
colnames(covariate) = c("FID","IID","Sex","Pheno")
pcs <- fread("merged_imputed_qc.eigenvec")
colnames(pcs) = c("FID","IID", paste0("PC",1:(ncol(pcs)-2)))
covariate$Pheno = NULL
# Read in phenotype
pheno <- read.delim("p.phen",header = F)
colnames(pheno) = c("FID","IID","Sex","Pheno")
pheno$Sex = NULL
# Summary statistics from plink logistic regression
ss <- read.delim("logistic_2pcs.PHENO1.glm.logistic.hybrid")
ss <- ss[ss$TEST=="ADD",]
# Remove P-value = 0, which causes problem in the transformation
ss <- ss[ss$P != 0,]
# Transform the P-values into correlation
cor <- p2cor(p = ss$P,
        n = nrow(pheno),
        sign = log(ss$OR)
        )
# Run the lassosum pipeline
# The cluster parameter is used for multi-threading
cl <- makeCluster(4)
out <- lassosum.pipeline(
    cor = cor,
    chr = ss$X.CHROM,
    pos = ss$POS,
    A1 = ss$A1,
    test.bfile = "merged_imputed_qc",
    LDblocks = "AFR.hg38", 
    cluster=cl
)
stopCluster(cl)
```

```{r}
cl <- makeCluster(4)
v <- validate(out, pheno = pheno, covar=covariate,cluster=cl)
# # Split-validation
# sv <- splitvalidate(out,cluster=cl)
# # Pseudo-validation
# pv <- pseudovalidate(out,cluster=cl)
stopCluster(cl)
```

```{r}
# Pull out lasso betas to identify SNPs in the model
betas = v$best.beta
sum(betas != 0)
```

# Questions 
1. How do we validate the PRS? Is there publicly available European data that we can compare this to?
2. What kind of validation (regular, pseudo, or split) would be best?
3. We are getting a huge number of significant SNPs (likely due at least partially to batch effects) in the PRS. We can use different p value cutoffs to only take the very top SNPS. What is a good number to aim for? This may result in much lower predictive ability.
  - Adjusting for 2 PCs results in 
  - Adjusting for 3 PCs results in 2077
  - Adjusting for 4 PCs results in 