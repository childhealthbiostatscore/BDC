---
title: "Polygenic Risk of T1D in Hispanic People"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(ggplot2)
library(pROC)
knitr::opts_chunk$set(echo = FALSE)
home_dir = ifelse(.Platform$OS.type != "unix","T:/",
                  "~/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/biobank_analysis/imputed/")
knitr::opts_knit$set(root.dir = home_dir)
```

# Methods

First, various p value thresholds were evaluated as outlined in `https://choishingwan.github.io/PRS-Tutorial/`. Because our p values are under-inflated, I used a range from $10^{-20}$ to $10^{-14}$. However, this approach has some serious drawbacks from a statistical point of view. In particular it is generally recommended that analysts choose a p value threshold that results in a "best fit" PRS, rather than choosing the threshold based on the number of SNPs it produces. 

Because these p value cutoffs produced a similar number of SNPs as the lasso (~100), I decided to continue with the lasso approach to avoid extra multiple comparison problems. Applying the lasso to the top 100 SNPs did not significantly reduce the number of SNPs in the final PRS.

All analyses were adjusted for 4 principal components in order to account for population stratification and batch effect.

# SNPs by QC Step

```{r}
pre_impute = read.table("/home/tim/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/biobank_analysis/merged_final.bim")
post_impute = read.table("./merged_imputed_qc.bim")
kimber = read.table("/home/tim/Dropbox/Work/Kimber Simmons/GWAS/Data_Raw/Simmons_Redo_Deliverable_061119_Final/raw_files/Simmons_redo.bim")
important_snps = read.csv("/home/tim/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/erin_snp_pos.csv")
lasso_snps = read.table("plink.lasso",header = T)
```

`r sum(paste0(important_snps$chr_name,":",important_snps$chrom_start) %in% paste0(kimber$V1,":",kimber$V4))` of the important SNPs were present in Kimber's data prior to all QC steps. After merging with the biobank data, there were `r sum(paste0(important_snps$chr_name,":",important_snps$chrom_start) %in% paste0(pre_impute$V1,":",pre_impute$V4))`. After imputation and additional QC, only `r sum(paste0(important_snps$chr_name,":",important_snps$chrom_start) %in% paste0(post_impute $V1,":",post_impute $V4))` remained.

# Lasso results

```{r message=FALSE}
train_res = read.table("./train.profile",header = T)
test_res = read.table("./test.profile",header = T)
roc(test_res$PHENO,test_res$SCORESUM,plot = T)
```

This PRS results in excellent prediction in this dataset. However, it is likely overfit to our data and should be validated on an external T1D dataset.

# SNP information

```{r}
# Import lasso variants

chr = sapply(strsplit(lasso_snps$SNP,":"),"[[",1)
pos = sapply(strsplit(lasso_snps$SNP,":"),"[[",2)
write.csv(paste0(chr,":",pos),"./lasso_snp_positions.csv",row.names = F)
```

# Questions 
1. plink's lasso function requires an $h^2$ estimate. Lam et al. table suggests 0.6 is reasonable, is this right?
![](/Users/timvigers/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/biobank_analysis/imputed/h2_table.png)
2. How do we validate these scores with external data? The AUC is really good for all models, which is concerning from an over-fitting point of view.