---
title: "Polygenic Risk of T1D in Hispanic People"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(ggplot2)
library(pROC)
knitr::opts_chunk$set(echo = FALSE)
home_dir = ifelse(.Platform$OS.type != "unix","T:/",
                  "~/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/biobank_analysis/imputed/")
knitr::opts_knit$set(root.dir = home_dir)
```

# Traditional PGRS Approach

```{r message=FALSE}
p_threshold = read.delim("range_list",header = F,sep = " ")
for(i in p_threshold$V1){
    prs = read.table(paste0("test.",i,".profile"),header = T)
    roc(prs$PHENO,prs$SCORE,plot = T)
}
```

# Lasso results

```{r}
prs = read.table("plink.profile",header = T)
roc(prs$PHENO,prs$SCORE,plot = T)
```

# Questions 
1. plink's lasso function requires an $h^2$ estimate. Lam et al. table suggests 0.6 is reasonable, is this right?
![](/Users/timvigers/Dropbox/Work/Kimber Simmons/GWAS/Data_Cleaned/biobank_analysis/imputed/h2_table.png)
2. How do we validate these scores with external data? The AUC is really good for all models, which is concerning from an over-fitting point of view.